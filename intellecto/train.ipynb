{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from intellecto import Intellecto\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from challengesimulator import ChallengeSimulator\n",
    "import gc\n",
    "from keras import backend as K\n",
    "\n",
    "N_GAMES_PER_EPISODE = 2500\n",
    "N_EPISODES = 30\n",
    "EPISODE_CHECKPOINT_FREQ = 5\n",
    "\n",
    "I = Intellecto()\n",
    "simulator = ChallengeSimulator()\n",
    "batch_size = N_GAMES_PER_EPISODE * (I.n_bubbles + I.queue_size)\n",
    "\n",
    "n_input = (I.n_bubbles + 1) * (I.n_bubbles + 2) \n",
    "n_output = I.n_bubbles\n",
    "\n",
    "PCA_MODEL_NAME = \"pca.model\"\n",
    "simulation_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(n_games=N_GAMES_PER_EPISODE):\n",
    "    f, l = I.play_episode(n_games=n_games)\n",
    "    #f = ipca.transform(f)\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordering_loss(ground_truth, predictions):\n",
    "    y = np.array(ground_truth)\n",
    "    y_ = np.array(predictions)\n",
    "    y = np.argsort(y, axis=1)\n",
    "    y_ = np.argsort(y_, axis=1)\n",
    "    diff_y = np.equal(y, y_)\n",
    "    loss_array = np.sum(diff_y, axis=1)\n",
    "    return np.mean(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca = None #joblib.load(PCA_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Validation Run #1\n",
      "Win ratio per difficulties [0.08, 0.47, 0.84, 0.95, 1.0]\n",
      "Win ratio mean 0.6679999999999999\n",
      "Ordering loss 1.5325714285714285\n",
      "\n",
      "\n",
      "Validation Run #2\n",
      "Win ratio per difficulties [0.05, 0.39, 0.7, 0.96, 1.0]\n",
      "Win ratio mean 0.6199999999999999\n",
      "Ordering loss 1.5051428571428571\n",
      "\n",
      "\n",
      "Validation Run #3\n",
      "Win ratio per difficulties [0.06, 0.43, 0.83, 0.93, 1.0]\n",
      "Win ratio mean 0.65\n",
      "Ordering loss 1.474\n",
      "\n",
      "\n",
      "Validation Run #4\n",
      "Win ratio per difficulties [0.02, 0.43, 0.82, 0.96, 1.0]\n",
      "Win ratio mean 0.646\n",
      "Ordering loss 1.4714285714285715\n",
      "\n",
      "\n",
      "Validation Run #5\n",
      "Win ratio per difficulties [0.04, 0.47, 0.79, 0.96, 0.99]\n",
      "Win ratio mean 0.65\n",
      "Ordering loss 1.5391428571428571\n",
      "\n",
      "\n",
      "Validation Run #6\n",
      "Win ratio per difficulties [0.04, 0.45, 0.76, 0.92, 1.0]\n",
      "Win ratio mean 0.634\n",
      "Ordering loss 1.4908571428571429\n",
      "\n",
      "\n",
      "Validation Run #7\n",
      "Win ratio per difficulties [0.04, 0.43, 0.75, 0.95, 1.0]\n",
      "Win ratio mean 0.634\n",
      "Ordering loss 1.465142857142857\n",
      "\n",
      "\n",
      "Validation Run #8\n",
      "Win ratio per difficulties [0.02, 0.38, 0.81, 0.96, 1.0]\n",
      "Win ratio mean 0.634\n",
      "Ordering loss 1.5025714285714287\n",
      "\n",
      "\n",
      "Validation Run #9\n",
      "Win ratio per difficulties [0.07, 0.42, 0.8, 0.93, 1.0]\n",
      "Win ratio mean 0.644\n",
      "Ordering loss 1.55\n",
      "\n",
      "\n",
      "Validation Run #10\n",
      "Win ratio per difficulties [0.05, 0.42, 0.8, 0.94, 1.0]\n",
      "Win ratio mean 0.642\n",
      "Ordering loss 1.5511428571428572\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.models import load_model\n",
    "from keras.metrics import mean_absolute_error, categorical_crossentropy\n",
    "\n",
    "MODEL_NAME = \"intellecto.hdf5\"\n",
    "batch_size = 16 #I.n_bubbles\n",
    "num_classes = I.n_bubbles\n",
    "epochs = 10\n",
    "input_size = n_input #ipca.n_components\n",
    "TRAIN_MODEL = False\n",
    "\n",
    "droprate = 0.6\n",
    "activation = 'elu'\n",
    "\n",
    "def getmodel():\n",
    "    try:\n",
    "        model = load_model(MODEL_NAME)\n",
    "        #print(\"Loaded saved model: \" + MODEL_NAME)\n",
    "    except:\n",
    "        print(\"Creating new model: \" + MODEL_NAME)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=1024, activation=activation, input_shape=(input_size, )))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate))\n",
    "\n",
    "        model.add(Dense(units=512, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate))\n",
    "\n",
    "        model.add(Dense(units=512, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "        model.add(Dense(units=512, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "        model.add(Dense(units=256, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "        model.add(Dense(units=256, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "        model.add(Dense(units=256, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2))\n",
    "\n",
    "        model.add(Dense(units=128, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2))\n",
    "\n",
    "        model.add(Dense(units=128, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2))\n",
    "\n",
    "        model.add(Dense(units=64, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2))\n",
    "\n",
    "        model.add(Dense(units=64, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2.5))\n",
    "\n",
    "        model.add(Dense(units=64, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 3))\n",
    "\n",
    "        model.add(Dense(units=32, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 3))\n",
    "\n",
    "        model.add(Dense(units=16, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 3.5))\n",
    "\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def validation_model(games_per_difficulty=100):\n",
    "        x_val, y_val = get_training_data(n_games=100)\n",
    "        saved_model = load_model(MODEL_NAME)\n",
    "        orderingloss = ordering_loss(ground_truth=y_val, predictions=saved_model.predict(x_val))\n",
    "        win_ratio_mean, win_ratio_per_difficulties = simulator.simulate_challenge_games(model=saved_model, ipca=ipca, \n",
    "                                                                                        games_per_difficulty=games_per_difficulty)\n",
    "        \n",
    "        return win_ratio_mean, win_ratio_per_difficulties, orderingloss\n",
    "        \n",
    "        \n",
    "def do_on_epoch_end(epoch, _):\n",
    "    if (epoch + 1) == epochs:\n",
    "        win_ratio_mean, win_ratio_per_difficulties, orderingloss = validation_model()\n",
    "        print(\"\\n\\nWin ratio per difficulties\", win_ratio_per_difficulties)\n",
    "        print(\"Win ratio mean\", win_ratio_mean)\n",
    "        print(\"Ordering loss\", orderingloss)\n",
    "        simulation_records.append(win_ratio_mean)\n",
    "        \n",
    "        \n",
    "if TRAIN_MODEL:\n",
    "    for n_episodes in range(N_EPISODES):\n",
    "        x, y = get_training_data()\n",
    "        model = getmodel()\n",
    "        print(\"\\n\\n\\nTraining on episode #\" + str(n_episodes + 1))\n",
    "        model.fit(\n",
    "            x, \n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=0,\n",
    "            validation_data=(x, y),\n",
    "            callbacks = [\n",
    "                ModelCheckpoint(MODEL_NAME, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='max', period=1),\n",
    "                LambdaCallback(on_epoch_end=do_on_epoch_end)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        if (n_episodes + 1) % EPISODE_CHECKPOINT_FREQ == 0:\n",
    "            print(\"\\nCurrent mean win ratio overall\", np.mean(simulation_records))\n",
    "            I.plot(y_data=simulation_records, y_label=\"win_ratio_mean\", window=EPISODE_CHECKPOINT_FREQ)\n",
    "            \n",
    "        model = None\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "            \n",
    "    print(\"\\nFinal mean win ratio overall\", np.mean(simulation_records))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    for n_val in range(10):\n",
    "        print(\"\\n\\nValidation Run #\" + str(n_val + 1))\n",
    "        win_ratio_mean, win_ratio_per_difficulties, orderingloss = validation_model()\n",
    "        print(\"Win ratio per difficulties\", win_ratio_per_difficulties)\n",
    "        print(\"Win ratio mean\", win_ratio_mean)\n",
    "        print(\"Ordering loss\", orderingloss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
