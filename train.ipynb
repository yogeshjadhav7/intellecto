{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from intellecto import Intellecto\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from challengesimulator import ChallengeSimulator\n",
    "import gc\n",
    "from keras import backend as K\n",
    "\n",
    "N_GAMES_PER_EPISODE = 2500\n",
    "N_EPISODES = 30\n",
    "EPISODE_CHECKPOINT_FREQ = 5\n",
    "\n",
    "I = Intellecto()\n",
    "simulator = ChallengeSimulator()\n",
    "batch_size = N_GAMES_PER_EPISODE * (I.n_bubbles + I.queue_size)\n",
    "\n",
    "n_input = (I.n_bubbles + 1) * (I.n_bubbles + 2) \n",
    "n_output = I.n_bubbles\n",
    "\n",
    "PCA_MODEL_NAME = \"pca.model\"\n",
    "simulation_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(n_games=N_GAMES_PER_EPISODE):\n",
    "    f, l = I.play_episode(n_games=n_games)\n",
    "    #f = ipca.transform(f)\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordering_loss(ground_truth, predictions):\n",
    "    y = np.array(ground_truth)\n",
    "    y_ = np.array(predictions)\n",
    "    y = np.argsort(y, axis=1)\n",
    "    y_ = np.argsort(y_, axis=1)\n",
    "    diff_y = np.equal(y, y_)\n",
    "    loss_array = np.sum(diff_y, axis=1)\n",
    "    return np.mean(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca = None #joblib.load(PCA_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.models import load_model\n",
    "from keras.metrics import mean_absolute_error, categorical_crossentropy\n",
    "\n",
    "MODEL_NAME = \"intellecto.hdf5\"\n",
    "batch_size = 16 #I.n_bubbles\n",
    "num_classes = I.n_bubbles\n",
    "epochs = 10\n",
    "input_size = n_input #ipca.n_components\n",
    "TRAIN_MODEL = True\n",
    "\n",
    "droprate = 0.6\n",
    "\n",
    "def activation(x):\n",
    "    return K.relu(x=x, alpha=0.5)\n",
    "\n",
    "def getmodel():\n",
    "    try:\n",
    "        model = load_model(MODEL_NAME, custom_objects={'activation': activation})\n",
    "        #print(\"Loaded saved model: \" + MODEL_NAME)\n",
    "    except:\n",
    "        print(\"Creating new model: \" + MODEL_NAME)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=1024, activation=activation, input_shape=(input_size, )))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate))\n",
    "\n",
    "        model.add(Dense(units=512, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate))\n",
    "\n",
    "        model.add(Dense(units=512, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "        model.add(Dense(units=512, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "        model.add(Dense(units=256, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "        model.add(Dense(units=256, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "        model.add(Dense(units=256, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2))\n",
    "\n",
    "        model.add(Dense(units=128, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2))\n",
    "\n",
    "        model.add(Dense(units=128, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2))\n",
    "\n",
    "        model.add(Dense(units=64, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2))\n",
    "\n",
    "        model.add(Dense(units=64, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 2.5))\n",
    "\n",
    "        model.add(Dense(units=64, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 3))\n",
    "\n",
    "        model.add(Dense(units=32, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 3))\n",
    "\n",
    "        model.add(Dense(units=16, activation=activation))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(droprate / 3.5))\n",
    "\n",
    "        #model.add(Dense(num_classes, activation='softmax'))\n",
    "        #model.add(Dense(num_classes, activation='sigmoid'))\n",
    "        model.add(Dense(num_classes, activation=None))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=[mean_absolute_error])\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def do_on_epoch_end(epoch, _):\n",
    "    if (epoch + 1) == epochs:\n",
    "        saved_model = load_model(MODEL_NAME, custom_objects={'activation': activation})\n",
    "        win_ratio_mean, win_ratio_per_difficulties = simulator.simulate_challenge_games(model=saved_model, ipca=ipca)\n",
    "        print(\"\\n\\nWin ratio per difficulties\", win_ratio_per_difficulties)\n",
    "        print(\"Win ratio mean\", win_ratio_mean)\n",
    "        orderingloss = ordering_loss(ground_truth=y, predictions=saved_model.predict(x))\n",
    "        print(\"Ordering loss\", orderingloss)\n",
    "        simulation_records.append(win_ratio_mean)\n",
    "        \n",
    "        \n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    for n_episodes in range(N_EPISODES):\n",
    "        x, y = get_training_data()\n",
    "        model = getmodel()\n",
    "        print(\"\\n\\n\\nTraining on episode #\" + str(n_episodes + 1))\n",
    "        model.fit(\n",
    "            x, \n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=0,\n",
    "            validation_data=(x, y),\n",
    "            callbacks = [\n",
    "                ModelCheckpoint(MODEL_NAME, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='min', period=1),\n",
    "                LambdaCallback(on_epoch_end=do_on_epoch_end)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        if (n_episodes + 1) % EPISODE_CHECKPOINT_FREQ == 0:\n",
    "            print(\"\\nCurrent mean win ratio overall\", np.mean(simulation_records))\n",
    "            I.plot(y_data=simulation_records, y_label=\"win_ratio_mean\", window=EPISODE_CHECKPOINT_FREQ)\n",
    "            \n",
    "        model = None\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "            \n",
    "    print(\"\\nFinal mean win ratio overall\", np.mean(simulation_records))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
