{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intellecto import Intellecto\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from challengesimulator import ChallengeSimulator\n",
    "\n",
    "N_GAMES_PER_EPISODE = 100\n",
    "N_EPISODES = 100\n",
    "EPISODE_CHECKPOINT_FREQ = 10\n",
    "\n",
    "I = Intellecto()\n",
    "simulator = ChallengeSimulator()\n",
    "batch_size = N_GAMES_PER_EPISODE * (I.n_bubbles + I.queue_size)\n",
    "\n",
    "n_input = (I.n_bubbles + 1) * (I.n_bubbles + 2) \n",
    "n_output = I.n_bubbles\n",
    "\n",
    "PCA_MODEL_NAME = \"pca.model\"\n",
    "simulation_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(n_games=N_GAMES_PER_EPISODE):\n",
    "    f, l = I.play_episode(n_games=n_games)\n",
    "    f = ipca.transform(f)\n",
    "    return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordering_loss(ground_truth, predictions):\n",
    "    y = np.array(ground_truth)\n",
    "    y_ = np.array(predictions)\n",
    "    y = np.argsort(y, axis=1)\n",
    "    y_ = np.argsort(y_, axis=1)\n",
    "    diff_y = np.abs(np.subtract(y, y_))\n",
    "    loss_array = np.sum(diff_y, axis=1)\n",
    "    return np.median(loss_array) / 12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca = joblib.load(PCA_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new model: intellecto.hdf5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              13312     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 1,410,309\n",
      "Trainable params: 1,402,661\n",
      "Non-trainable params: 7,648\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Training on episode #1\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1614.82759, saving model to intellecto.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1614.82759 to 1321.86381, saving model to intellecto.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1321.86381 to 1119.23990, saving model to intellecto.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1119.23990 to 1027.98047, saving model to intellecto.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      "Win ratio per difficulties [0.01, 0.05, 0.51, 0.96, 1.0]\n",
      "Win ratio mean 0.506\n",
      "Final mean win ratio overall 0.506\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.models import load_model\n",
    "from keras.metrics import mean_absolute_error, categorical_crossentropy\n",
    "\n",
    "MODEL_NAME = \"intellecto.hdf5\"\n",
    "batch_size = I.n_bubbles\n",
    "num_classes = I.n_bubbles\n",
    "epochs = 10\n",
    "input_size = ipca.n_components\n",
    "TRAIN_MODEL = True\n",
    "\n",
    "droprate = 0.6\n",
    "activation = 'elu'\n",
    "try:\n",
    "    model = load_model(MODEL_NAME)\n",
    "    print(\"Loaded saved model: \" + MODEL_NAME)\n",
    "except:\n",
    "    print(\"Creating new model: \" + MODEL_NAME)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1024, activation=activation, input_shape=(input_size, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "    \n",
    "    model.add(Dense(units=512, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate))\n",
    "\n",
    "    model.add(Dense(units=512, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "    model.add(Dense(units=512, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 1.5))\n",
    "    \n",
    "    model.add(Dense(units=256, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 1.5))\n",
    "    \n",
    "    model.add(Dense(units=256, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 1.5))\n",
    "\n",
    "    model.add(Dense(units=256, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 2))\n",
    "    \n",
    "    model.add(Dense(units=128, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 2))\n",
    "    \n",
    "    model.add(Dense(units=128, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 2))\n",
    "\n",
    "    model.add(Dense(units=64, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 2))\n",
    "    \n",
    "    model.add(Dense(units=64, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 2.5))\n",
    "    \n",
    "    model.add(Dense(units=64, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 3))\n",
    "\n",
    "    model.add(Dense(units=32, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 3))\n",
    "    \n",
    "    model.add(Dense(units=16, activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(droprate / 3.5))\n",
    "\n",
    "    #model.add(Dense(num_classes, activation='softmax'))\n",
    "    #model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    model.add(Dense(num_classes, activation=None))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[mean_absolute_error])\n",
    "\n",
    "def do_on_epoch_end(epoch, _):\n",
    "    if (epoch + 1) == epochs:\n",
    "        saved_model = load_model(MODEL_NAME)\n",
    "        win_ratio_mean, win_ratio_per_difficulties = simulator.simulate_challenge_games(model=saved_model, ipca=ipca)\n",
    "        print(\"\\nWin ratio per difficulties\", win_ratio_per_difficulties)\n",
    "        print(\"Win ratio mean\", win_ratio_mean)\n",
    "        simulation_records.append(win_ratio_mean)\n",
    "        \n",
    "        \n",
    "if TRAIN_MODEL:\n",
    "    for n_episodes in range(N_EPISODES):\n",
    "        print(\"\\n\\n\\nTraining on episode #\" + str(n_episodes + 1))\n",
    "        x, y = get_training_data()\n",
    "        model.fit(\n",
    "            x, \n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=0,\n",
    "            validation_data=(x, y),\n",
    "            callbacks = [\n",
    "                ModelCheckpoint(MODEL_NAME, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='min', period=1),\n",
    "                LambdaCallback(on_epoch_end=do_on_epoch_end)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        if (n_episodes + 1) % EPISODE_CHECKPOINT_FREQ == 0:\n",
    "            print(\"Current mean win ratio overall\", np.mean(simulation_records))\n",
    "            I.plot(y_data=simulation_records, y_label=\"win_ratio_mean\", window=EPISODE_CHECKPOINT_FREQ)\n",
    "            \n",
    "        model = None\n",
    "        model = load_model(MODEL_NAME)\n",
    "            \n",
    "    print(\"Final mean win ratio overall\", np.mean(simulation_records))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
